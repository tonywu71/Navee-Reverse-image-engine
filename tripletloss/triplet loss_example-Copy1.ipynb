{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <font size='6' font-weight='bold'> Tripletloss Part </font> </center>  \n",
    "<center> <i> Projet Navee</i> </center>\n",
    "<center> <i> Matheus, Bruno and Tony </i> </center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pylab import *\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform,he_uniform\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model,normalize\n",
    "\n",
    "from sklearn.metrics import roc_curve,roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change to main file tree level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Tony/Desktop/projet-navee/tripletloss'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Tony/Desktop/projet-navee'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data.data import * # imports data.py\n",
    "from data.Data_Gen import * # imports Data_Gen.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'data/database_BAM.sqlite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the database has been correctly imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset found ü§ôüèª\n"
     ]
    }
   ],
   "source": [
    "assert os.path.exists(db_path), \"Database not found üëéüèª\\n\\\n",
    "    Please check that you've successfully copied the database in the data\\\n",
    "    directory after having cloned the project ‚ÄºÔ∏è\"\n",
    "print ('Dataset found ü§ôüèª')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples and tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a data_base object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = data_base(db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`db` is a custom object defined in `data.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'classes', 'classes_emotions', 'classes_labels', 'classes_labels_emotions', 'classes_labels_media', 'classes_media', 'file_path', 'get_image', 'get_images', 'get_images_', 'get_images_emotions', 'get_images_labels', 'get_images_media', 'get_label', 'get_label_emotions', 'get_label_labels', 'get_label_media', 'mids', 'return_classes', 'train_test_split']\n"
     ]
    }
   ],
   "source": [
    "print(dir(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (224,224) # resize parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x):\n",
    "    x = x.convert('RGB')\n",
    "    x = x.resize(image_size)\n",
    "    x = np.array(x)\n",
    "    x = x / 255.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['content_building', 'emotion_happy', 'content_flower', 'content_bicycle', 'media_comic', 'content_people', 'media_3d_graphics', 'content_dog', 'media_vectorart', 'emotion_scary', 'emotion_gloomy', 'media_graphite', 'emotion_peaceful', 'media_pen_ink', 'content_cars', 'media_oilpaint', 'content_cat', 'content_tree', 'content_bird', 'media_watercolor']\n"
     ]
    }
   ],
   "source": [
    "print(list(db.classes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_list = list(db.classes.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a subset of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_images = 500 # number of images to extract from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = db.get_images_(nb_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {i:db.get_label(i) for i in IDs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`labels` have the shape:  \n",
    "{4288:\n",
    "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.7\n",
    "\n",
    "partition = {}\n",
    "\n",
    "partition['train'] = IDs[:int(train_ratio * len(IDs))]\n",
    "partition['test'] = IDs[int(train_ratio*len(IDs)):len(IDs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `DataGenerator_training` in order to train with the downloaded images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator_training(partition['train'], classes_list, db=db, batch_size=batch_size, pre=preprocess)\n",
    "validation_generator = DataGenerator_training(partition['test'], classes_list, db=db, batch_size=batch_size, pre=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_generator` est un tenseur tel que :\n",
    "\n",
    "- La premi√®re dimension donne le nombre d'√©l√©ments dans un batch.\n",
    "- La deuxi√®me dimension a une dimension de 2, le premier axe donne les batchs tandis que le 2√®me axe donne la liste des classes.\n",
    "- La troisi√®me dimension donne les √©l√©ments du batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ÄºÔ∏èIMPORTANT: ‚ÄºÔ∏è**  \n",
    "Calling `train_generator[0][0][0]` downloads a full batch of images. Thus we'll be careful never to call `train_generator[0][0][0]` but to instead set `current_batch = train_generator[0][0]` and then to browse through `current_batch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it's okay since we only display one image, but there are risks that a naive loop gives a complexity in O(n!) instead of O(n) ‚ò†Ô∏è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<data.Data_Gen.DataGenerator_training object at 0x139a56c90>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_DataGenerator__data_generation',\n",
       " '_DataGenerator_training__data_generation',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'batch_size',\n",
       " 'db',\n",
       " 'dim',\n",
       " 'indexes',\n",
       " 'list_IDs',\n",
       " 'lista',\n",
       " 'n_channels',\n",
       " 'n_classes',\n",
       " 'on_epoch_end',\n",
       " 'pre',\n",
       " 'shuffle',\n",
       " 'use_sequence_api']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_IDs = [171966541, 16777352, 54526109, 129050139, 34253499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataGenerator_training' object has no attribute '__data_generation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-62f8efe60512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__data_generation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_IDs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataGenerator_training' object has no attribute '__data_generation'"
     ]
    }
   ],
   "source": [
    "train_generator.__data_generation(list_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_generator[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting class number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.argmax(train_generator[0][1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TripletLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawPics(data_generator, nb=0, template='{}', batch_nb=0):\n",
    "    if (nb==0):\n",
    "        N = data_generator.batch_size\n",
    "    else:\n",
    "        N = min(nb, data_generator.batch_size)\n",
    "        \n",
    "    fig=plt.figure(figsize=(16,2))\n",
    "    \n",
    "    nbligne = floor(N/20)+1\n",
    "    current_batch = data_generator[batch_nb]\n",
    "    current_batch_x = current_batch[0]\n",
    "    current_batch_y = current_batch[1]\n",
    "    \n",
    "    for m in range(N):\n",
    "        subplot = fig.add_subplot(nbligne,min(N,20),m+1)\n",
    "        axis(\"off\")\n",
    "        plt.imshow(current_batch_x[m],vmin=0, vmax=1,cmap='Greys')\n",
    "        \n",
    "        class_nb = np.argmax(current_batch_y[m])\n",
    "        subplot.title.set_text((template.format(str(class_nb))))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = train_generator.n_classes\n",
    "img_rows, img_cols = train_generator.dim\n",
    "input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "DrawPics(train_generator, nb=5, template='Train {}', batch_nb=0)\n",
    "#DrawPics(validation_generator, nb=5, template='Test {}', batch_nb=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDataSet(data_generator):\n",
    "    \"\"\"Build dataset (numpy array) for faster and easier data manipulation.\n",
    "    \n",
    "    \n",
    "    returns:\n",
    "        dataset : list of lengh 10 containing images for each classes of shape (?,28,28,1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # STEP 1: Removing the batch structure and separating images from labels.\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for batch_nb in range(len(data_generator)):\n",
    "        print(f'batch_nb = {batch_nb}')\n",
    "        current_batch = data_generator[batch_nb]\n",
    "\n",
    "        for idx in range(len(current_batch)):\n",
    "            print(f'idx = {idx}')\n",
    "            x_train.append(current_batch[0][idx])\n",
    "            y_train.append(np.argmax(current_batch[1][idx]))\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "   \n",
    "    \n",
    "    #Sorting images by classes\n",
    "    nb_classes = data_generator.n_classes\n",
    "    img_rows, img_cols = data_generator.dim\n",
    "    \n",
    "    x_train_sorted = []\n",
    "    for n in range(nb_classes):\n",
    "        x_train_sorted.append(np.asarray([img for idx, img in enumerate(x_train) if y_train[idx]==n]))\n",
    "    \n",
    "    return x_train, y_train, x_train_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDataSet(data_generator):\n",
    "    \"\"\"Build dataset (numpy array) for faster and easier data manipulation.\n",
    "    \n",
    "    \n",
    "    returns:\n",
    "        dataset : list of lengh 10 containing images for each classes of shape (?,28,28,1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # STEP 1: Removing the batch structure and separating images from labels.\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for current_batch in data_generator:\n",
    "        print('next batch')\n",
    "        \n",
    "        for idx in range(len(current_batch[0])):\n",
    "            x_train.append(current_batch[0][idx])\n",
    "            y_train.append(np.argmax(current_batch[1][idx]))\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "   \n",
    "    \n",
    "    #Sorting images by classes\n",
    "    nb_classes = data_generator.n_classes\n",
    "    img_rows, img_cols = data_generator.dim\n",
    "    \n",
    "    x_train_sorted = []\n",
    "    for n in range(nb_classes):\n",
    "        x_train_sorted.append(np.asarray([img for idx, img in enumerate(x_train) if y_train[idx]==n]))\n",
    "    \n",
    "    return x_train, y_train, x_train_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "x_train, y_train, x_train_sorted = buildDataSet(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'x_train.shape = {x_train.shape}, should be ({nb_images}, {img_rows}, {img_cols}, 3)')\n",
    "print(f'y_train.shape = {y_train.shape}, should be ({nb_images},)')\n",
    "print(f'x_train_sorted.shape = {len(x_train_sorted)}, should be {train_generator.n_classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing batch for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_all_classes(X):\n",
    "    ''' Return True if all classes are represented in X.'''\n",
    "    nb_classes = len(X)\n",
    "    l_isNull = [X[class_idx].shape[0]==0 for class_idx in range(nb_classes)]\n",
    "    return not(any(l_isNull))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_all_classes(x_train_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_random(X, batch_size):\n",
    "    \"\"\"\n",
    "    Create batch of APN triplets with a complete random strategy\n",
    "    \n",
    "    Arguments:\n",
    "    x_train -- x_train generated from BuildDataSet \n",
    "\n",
    "    Returns:\n",
    "    triplets -- list containing 3 tensors A,P,N of shape (batch_size,w,h,c)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    nb_classes = len(X)\n",
    "    \n",
    "    m, w, h, c = X[0].shape\n",
    "    \n",
    "    assert has_all_classes(X), 'Not all classes are represented in X!'\n",
    "    \n",
    "    # initialize result\n",
    "    triplets=[np.zeros((batch_size,h, w,c)) for i in range(3)]\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        #Pick one random class for anchor\n",
    "        anchor_class = np.random.randint(0, nb_classes)\n",
    "        nb_sample_available_for_class_AP = X[anchor_class].shape[0]\n",
    "        \n",
    "        \n",
    "        #Pick two different random pics for this class => A and P\n",
    "        [idx_A,idx_P] = np.random.choice(nb_sample_available_for_class_AP,size=2,replace=False)\n",
    "        \n",
    "        #Pick another class for N, different from anchor_class\n",
    "        negative_class = (anchor_class + np.random.randint(1,nb_classes)) % nb_classes\n",
    "        nb_sample_available_for_class_N = X[negative_class].shape[0]\n",
    "        \n",
    "        #Pick a random pic for this negative class => N\n",
    "        idx_N = np.random.randint(0, nb_sample_available_for_class_N)\n",
    "\n",
    "        triplets[0][i,:,:,:] = X[anchor_class][idx_A,:,:,:]\n",
    "        triplets[1][i,:,:,:] = X[anchor_class][idx_P,:,:,:]\n",
    "        triplets[2][i,:,:,:] = X[negative_class][idx_N,:,:,:]\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = get_batch_random(x_train_sorted, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawTriplets(tripletbatch, nbmax=None):\n",
    "    \"\"\"display the three images for each triplets in the batch\n",
    "    \"\"\"\n",
    "    labels = [\"Anchor\", \"Positive\", \"Negative\"]\n",
    "\n",
    "    if (nbmax==None):\n",
    "        nbrows = tripletbatch[0].shape[0]\n",
    "    else:\n",
    "        nbrows = min(nbmax,tripletbatch[0].shape[0])\n",
    "                 \n",
    "    for row in range(nbrows):\n",
    "        fig=plt.figure(figsize=(16,2))\n",
    "    \n",
    "        for i in range(3):\n",
    "            subplot = fig.add_subplot(1,3,i+1)\n",
    "            axis(\"off\")\n",
    "            plt.imshow(tripletbatch[i][row,:,:])\n",
    "            subplot.title.set_text(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawTriplets(triplets, nbmax=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A PARTIR D'ICI PAS ENCORE TESTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Neural Network for computing triplet similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss for triplet loss :**  \n",
    "$\\mathcal{L}(a, p, n) = \\max(0, d(a, p) ‚Äî d(a, n) + \\alpha)$\n",
    "where $\\alpha$ is the margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.4):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss function\n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor data\n",
    "            positive -- the encodings for the positive data (similar to anchor)\n",
    "            negative -- the encodings for the negative data (different from anchor)\n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    print('y_pred.shape = ',y_pred)\n",
    "    \n",
    "    total_lenght = y_pred.shape.as_list()[-1]\n",
    "#     print('total_lenght=',  total_lenght)\n",
    "#     total_lenght =12\n",
    "    \n",
    "    anchor = y_pred[:,0:int(total_lenght*1/3)]\n",
    "    positive = y_pred[:,int(total_lenght*1/3):int(total_lenght*2/3)]\n",
    "    negative = y_pred[:,int(total_lenght*2/3):int(total_lenght*3/3)]\n",
    "\n",
    "    # distance between the anchor and the positive\n",
    "    pos_dist = K.sum(K.square(anchor-positive),axis=1)\n",
    "\n",
    "    # distance between the anchor and the negative\n",
    "    neg_dist = K.sum(K.square(anchor-negative),axis=1)\n",
    "\n",
    "    # compute loss\n",
    "    basic_loss = pos_dist-neg_dist+alpha\n",
    "    loss = K.maximum(basic_loss,0.0)\n",
    " \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`input_shape = (img_rows, img_cols, 1)` has been previously defined like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(in_dims):\n",
    "    \"\"\"\n",
    "    Base network to be shared.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(128,(7,7),padding='same',input_shape=(in_dims[0],in_dims[1],in_dims[2],),activation='relu',name='conv1'))\n",
    "    model.add(MaxPooling2D((2,2),(2,2),padding='same',name='pool1'))\n",
    "    model.add(Conv2D(256,(5,5),padding='same',activation='relu',name='conv2'))\n",
    "    model.add(MaxPooling2D((2,2),(2,2),padding='same',name='pool2'))\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(4,name='embeddings'))\n",
    "    # model.add(Dense(600))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_optim = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_input = Input((28,28,1, ), name='anchor_input')\n",
    "positive_input = Input((28,28,1, ), name='positive_input')\n",
    "negative_input = Input((28,28,1, ), name='negative_input')\n",
    "\n",
    "# Shared embedding layer for positive and negative items\n",
    "Shared_DNN = create_base_network([28,28,1,])\n",
    "\n",
    "\n",
    "encoded_anchor = Shared_DNN(anchor_input)\n",
    "encoded_positive = Shared_DNN(positive_input)\n",
    "encoded_negative = Shared_DNN(negative_input)\n",
    "\n",
    "\n",
    "merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1, name='merged_layer')\n",
    "\n",
    "model = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
    "model.compile(loss=triplet_loss, optimizer=adam_optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Anchor = X_train[:,0,:].reshape(-1,28,28,1)\n",
    "Positive = X_train[:,1,:].reshape(-1,28,28,1)\n",
    "Negative = X_train[:,2,:].reshape(-1,28,28,1)\n",
    "Anchor_test = X_test[:,0,:].reshape(-1,28,28,1)\n",
    "Positive_test = X_test[:,1,:].reshape(-1,28,28,1)\n",
    "Negative_test = X_test[:,2,:].reshape(-1,28,28,1)\n",
    "\n",
    "Y_dummy = np.empty((Anchor.shape[0],300))\n",
    "Y_dummy2 = np.empty((Anchor_test.shape[0],1))\n",
    "\n",
    "model.fit([Anchor,Positive,Negative],y=Y_dummy,validation_data=([Anchor_test,Positive_test,Negative_test],Y_dummy2), batch_size=512, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = Model(inputs=anchor_input, outputs=encoded_anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model.load_weights('triplet_model_MNIST.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
