{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pylab import *\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform,he_uniform\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model,normalize\n",
    "\n",
    "from sklearn.metrics import roc_curve,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawPics(tensor,nb=0,template='{}',classnumber=None):\n",
    "    if (nb==0):\n",
    "        N = tensor.shape[0]\n",
    "    else:\n",
    "        N = min(nb,tensor.shape[0])\n",
    "    fig=plt.figure(figsize=(16,2))\n",
    "    nbligne = floor(N/20)+1\n",
    "    for m in range(N):\n",
    "        subplot = fig.add_subplot(nbligne,min(N,20),m+1)\n",
    "        axis(\"off\")\n",
    "        plt.imshow(tensor[m,:,:,0],vmin=0, vmax=1,cmap='Greys')\n",
    "        if (classnumber!=None):\n",
    "            subplot.title.set_text((template.format(classnumber)))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "def buildDataSet():\n",
    "    \"\"\"Build dataset for train and test\n",
    "    \n",
    "    \n",
    "    returns:\n",
    "        dataset : list of lengh 10 containing images for each classes of shape (?,28,28,1)\n",
    "    \"\"\"\n",
    "    (x_train_origin, y_train_origin), (x_test_origin, y_test_origin) = mnist.load_data()\n",
    "\n",
    "    assert K.image_data_format() == 'channels_last'\n",
    "    x_train_origin = x_train_origin.reshape(x_train_origin.shape[0], img_rows, img_cols, 1)\n",
    "    x_test_origin = x_test_origin.reshape(x_test_origin.shape[0], img_rows, img_cols, 1)\n",
    "    \n",
    "    dataset_train = []\n",
    "    dataset_test = []\n",
    "    \n",
    "    #Sorting images by classes and normalize values 0=>1\n",
    "    for n in range(nb_classes):\n",
    "        images_class_n = np.asarray([row for idx,row in enumerate(x_train_origin) if y_train_origin[idx]==n])\n",
    "        dataset_train.append(images_class_n/255)\n",
    "        \n",
    "        images_class_n = np.asarray([row for idx,row in enumerate(x_test_origin) if y_test_origin[idx]==n])\n",
    "        dataset_test.append(images_class_n/255)\n",
    "        \n",
    "    return dataset_train,dataset_test,x_train_origin,y_train_origin,x_test_origin,y_test_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking shapes for class 0 (train) :  (5923, 28, 28, 1)\n",
      "Checking shapes for class 0 (test) :  (980, 28, 28, 1)\n",
      "Checking first samples\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA10AAACLCAYAAACa9PPwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAVS0lEQVR4nO3deYwUZbfH8fOwiTjsQUBFFIGACHFDcLkRBUyMsogKosh1QSFGMcQNVAQMLoiC4IJbVISJqMAVNEEkImCiKOJCorgrV64yIpsgq1L3D8bOnONQ0zVdT3V1v99PQt76TXVVPbyc7unHrtOPC4JAAAAAAAB+1Mj3AAAAAACgmDHpAgAAAACPmHQBAAAAgEdMugAAAADAIyZdAAAAAOARky4AAAAA8IhJFwAAAAB4VHCTLufcjgp/9jvndlXIV1TjfMucc8OqeMyJzrnVzrmd5f97YvX/BkA4ahzFjPpGsaPGUeyo8eopuElXEAQl//wRkf8VkT4VflYa9/Wcc3VEZIGIzBaRxiIyU0QWlP8ciB01jmJGfaPYUeModtR49RTcpOtgnHM1nHOjnXPfO+c2Oededc41Kd9X1zk3u/znW51zq5xzzZ1z94nIf4nI4+Wz88crOXUPEaklIo8GQbAnCILpIuJE5Nyk/m6ACDWO4kZ9o9hR4yh21Hi4opl0ichIEekvImeLyBEiskVEnijf998i0lBEWolIUxEZISK7giC4S0TeE5Eby2fnN1Zy3k4isiYIgqDCz9aU/xxIEjWOYkZ9o9hR4yh21HiIYpp0DReRu4IgWB8EwR4RGS8ilzjnaonIPjnwD9w2CIK/gyBYHQTBH1met0REtpmfbROR+jGNG8gWNY5iRn2j2FHjKHbUeIha+R5AjFqLyP845/ZX+NnfItJcRGbJgZn1HOdcIzlwT+hdQRDsy+K8O0SkgflZAxHZnvuQgUiocRQz6hvFjhpHsaPGQxTTJ10/i8j5QRA0qvCnbhAE/xcEwb4gCCYEQXC8iJwhIheKyNDy44KDnvGAL0Ski3POVfhZl/KfA0mixlHMqG8UO2ocxY4aD1FMk66nROQ+51xrERHnXDPnXL/y7XOcc52dczVF5A858BHn3+XHlYlIm5DzLit/7Ejn3CHOuX/uNV3q4e8AhKHGUcyobxQ7ahzFjhoPUUyTrmkislBE3nbObReRlSLSrXxfCxGZKwf+kdeKyHI58LHmP8dd4pzb4pybbk8aBMFeOdAUOFREtorINSLSv/znQJKocRQz6hvFjhpHsaPGQzj9RSAAAAAAgDgV0yddAAAAAJA6TLoAAAAAwCMmXQAAAADgEZMuAAAAAPCISRcAAAAAeFSriv18tWHhcVU/BBVQ44WHGo+GGi881Hj2qO/CQ31HQ40XnkprnE+6AAAAAMAjJl0AAAAA4BGTLgAAAADwiEkXAAAAAHjEpAsAAAAAPGLSBQAAAAAeMekCAAAAAI+YdAEAAACAR0y6AAAAAMAjJl0AAAAA4BGTLgAAAADwiEkXAAAAAHjEpAsAAAAAPGLSBQAAAAAeMekCAAAAAI9q5XsAvuzdu1fliRMnZrbvu+8+ta9Hjx4qz58/X+WGDRvGOzigGr799luVjzvuOJU3btyY2V68eLHaZ2t6wIABodc6/fTTVW7Xrl3W4wQARLd///7M9urVq9W+e++9V+U777xT5Vq1or2d69Kli8qHHHJIpOMBRMcnXQAAAADgEZMuAAAAAPDIBUEQtj90Z5pt2rRJ5RYtWhz0sRU/0hcRmTdvnsr9+/ePb2D+uXwPoMCkpsb37Nmj8vXXX6+yrcvDDjvsoMf/8ccfOY2lXr16KpeUlKj8+uuvq9y9e/ecrhcRNR5Namo8qt27d6v8008/ZbbfeOMNte/2229XuUYN/d8Uhw8frvKxxx6r8g033KCyfX4ljBrPXsHWt7Vv377Mdt26db1ea8yYMSpXbMFIAPUdTWpqfOvWrSo3btxYZef0P62dY9j9YW699VaVjz76aJVPPPFElc8888xqX8uDSi/OJ10AAAAA4BGTLgAAAADwiEkXAAAAAHhUND1dO3fuVPmSSy5RecmSJQc9lp6u/2ipqfGxY8eqbJc2qMrJJ5+c2W7VqpXaV9WyB/Y5MHv27NDH2/N98cUXKh9xxBGhx+eIGo8mNTVu/f333yrPmjVL5fHjx6u8fv36g54rl94BEZFRo0apPHny5EjHx4waz15q6tsuVbNu3TqV7de6277CJHu6bM9jo0aNVP7www9VbtOmTZyXp76jSU2N256upk2b5mkk//baa6+pfNFFF6mccI8XPV0AAAAAkDQmXQAAAADgEZMuAAAAAPCoYHu65s6dq/KcOXNUXrBgQdbnsv0sdj2Xnj17qtylSxeV27Vrl/W1EsC90tHkrcY3bNigsl1z4rffflP5mGOOUXnRokUqt2zZMrNt+wHq1KkTOhb7OjBjxgyVR44cqbLtxRk2bJjKjz32mMox9ydQ49Gk9nV8/vz5Kg8cOLDa57K9t3Ytuaj++uuvnI7PETWevdTU94MPPqjyXXfdpXKDBg1Ufuutt1Tu2rVrZtuuUTRt2rQ4hpi1r7/+WuW2bdvGeXrqO5rU1LhdT/S5555Tedy4cSpv2bLF+5gOZvPmzSpX1dseM3q6AAAAACBpTLoAAAAAwCMmXQAAAADgUcH2dNWsWVNlu+ZEFLanq6pz2R6uxYsXq2zXSEoY90pHk7ca//HHH1U+7rjjVLZrSuRz/bipU6eqfMcdd6hs+18++eQTlW2/Wo6o8WhS8zpu+xgrri0n8u8+xjAzZ85U+bLLLlPZ9sDcfvvtWZ9bhJ6uApJYfdt1uKZMmaLyhAkTQh9v3XPPPSpX7If5/PPP1b4RI0aovGrVKpWreC8XmX1u2uvliPqOJjWv4VWx72tsL2DF/vJrr71W7bPf1bBx48acxmL7evv06ZPT+SKipwsAAAAAksakCwAAAAA8YtIFAAAAAB4VTE/XkCFDVC4tLVU5l56uww8/XGW7lsZ3330X6Xx2DaOEca90NHmr8W+++UblDh06qHzLLbeoPHnyZO9jylbHjh1Vtmu62DVmHnrooTgvT41Hk5q16EaPHq3yrFmzVLZ9jLZ/9t13381sN2/ePPRY+zq8fv16lc844wyVy8rKVD711FNVXrlypSSIGs9eYvVte7buvffenM7Xu3dvlV9++eXMduPGjUOPtb8fHn30UZUnTpyosq3fN998M/T89erVU3n58uWZbdvvVQ3UdzSpeS9u2ddZ26dlX+MHDx6c2Z49e7bat337dpXtGmB23Tu7Zphl19T94IMPVI55/VCLni4AAAAASBqTLgAAAADwiEkXAAAAAHiU2p4u2+/Sr1+/0P1Rerruvvtule1399evX1/lJUuWqHzzzTeHnt+up9S3b9+sxxYD7pWOJm81bmv6jTfeUHnhwoUqX3jhhd7HlC27voztH7D3/H/88cdxXp4ajyZvNb5s2TKVe/bsqbJdI7HiGi4iIi+88ILKl19+eWxje+SRR1S2/WZ2nS67/4EHHohtLJWgxrMXW33v27dP5enTp6s8ZswYlePu316zZk1mu1OnTqGP3b17t8p2jbsjjzxS5Z07d6o8YMAAlZcuXRp6vYp9upMmTQp9bBao72hS09Nla37GjBkq2/fHdp2uiu8F7Hvtqti1GF977bVIx2/btk3lkpKSSMdHRE8XAAAAACSNSRcAAAAAeMSkCwAAAAA8Sk1P19atW1U+4YQTVLZrqNheANvTZdd3ueaaazLb9p7T2rVrh47N3gfauXNnlX/99VeVDz30UJWfeeYZlS+99FKVa9asGXr9iLhXOprEanzLli0qn3nmmSrbGl+1apXKbdq08TOwarBrvtg1j+jpSpW89QPcdNNNKtv7/+3vn4EDB6pccd0i304//XSVP/roI5Xt83XFihU+h0ONZy+2+ravud27d4/r1JU67bTTVF6wYEFm264fGrfNmzer3KxZs9DHn3/++Zltu75So0aNol6e+o4mNT1d9r1606ZNQx9v3//adbyiWLt2rcp2LUXb52jNnz9fZdtXHzN6ugAAAAAgaUy6AAAAAMAjJl0AAAAA4FGtfA/gH/a7/21/S1UuuugilV988UWV69WrV61xiYg0bNhQ5alTp6ps1w74888/Vb7yyitVPu+881Ru0qRJtceGwvHKK6+o/NVXX6l83XXXqZymHi4gG7t27VL5nXfeiXT8iBEj4hxOJDfeeKPKQ4cOzdNIkC92na642T6tij1cle33KerfddGiRZnt77//Xu075ZRTYhkT0s+uJ2r17t1b5UGDBsV27Y4dO6ps1y6dO3du6PGffvqpyp57uirFJ10AAAAA4BGTLgAAAADwiEkXAAAAAHiUmp6uqM4991yVn332WZVz6eGqSq9evVQ+55xzVI7ax4D/DHa9isaNG6t82223JTkcIHa21+Obb74JfXzfvn1V7tatW+xjisuGDRtU3rFjh8olJSVJDgcenHXWWSo7F+9yUnaNziR7uCz73AMq88svv6g8fvx4le26tPY7D3y+Ltp1IKvq6UoDPukCAAAAAI+YdAEAAACAR6m9vXD//v2h+5csWZLQSP4tCAKV7dfdVzX2CRMmqDxt2rR4BoaC0rVrV5Xbtm2bp5EA8fjwww8jPX7SpEkq161bN87hxOqHH35Qed26dSp36tQpyeGgAFx77bUq23oH0u7pp59W+aefflJ54MCBKtuvdYfGJ10AAAAA4BGTLgAAAADwiEkXAAAAAHiUmp6u5557TuUaNdI7H7RfCb9ixQqV7dhtHjdunJ+BIVX27t2r8p49e/I0EiAZf/75p8q2/9Vq3769z+HkxPbmpvl3EtLB9uk+9dRTKvusobKyMpVPO+00lX///XeVo/4+GjVqVGb7pJNOijg6FIrdu3erPHPmzNDHDx8+3Odwig6/RQAAAADAIyZdAAAAAOARky4AAAAA8Cg1PV2lpaX5HkLGzp07VV6/fr3KN998c6TztWzZUuWaNWtWb2AoKMuXL1d57dq1Krdq1SrJ4cTqlVdeCd1fu3bthEaCNFm5cqXKzrk8jSR3tv+mkP8uSIatkTh7uBYvXqzy+++/H7rfvm+Jqn79+ioPGzYss01/Y/Gyfbg///xznkZSnHjmAAAAAIBHTLoAAAAAwCMmXQAAAADgUWp6utJkypQpKk+YMCHS8XbtmYULF6rcsGHD6g0MyBN7X/esWbNCHz9jxgyfwwES16BBg9CMwmf7WaL28e3YsUPldevWRTp+7NixmW27/uemTZtUtr3ncVu6dKnKHTp08Ho9wLfOnTvnewh80gUAAAAAPjHpAgAAAACPmHQBAAAAgEf0dInIkCFDVF69enVO5+vatavK7dq1y+l8QNJsD9fkyZNV3rx5s8oXXHCByl26dPEzMMCTxx57LHS/7VMs5HX2UDm7BmdVNWF9+eWXKrdp0ybnMSWlT58+Krdt2zZPI0Eh+fTTT1Xu0aNHfgZSCduHaN+n5AOfdAEAAACAR0y6AAAAAMAjJl0AAAAA4FFqerrs+hj79+8Pffznn38eur9fv34q2x6VsGvVqJHbXPSll17K6XgUB9vzkeb12exzYNKkSSo/+eSTKrdu3Vpl2/uQ63MIhcn2/i1fvlzlsrIylW+77bbQ45P0yy+/qNyiRQuVL7744iSHgzy44oorVI7a05Vmhx9+uMrdunVTefbs2SqXlJR4HxMK39SpU1W++uqrVW7UqJG3a3/yySeh+/v27aty3bp1vY0lW7wzAgAAAACPmHQBAAAAgEdMugAAAADAI2d7qYzQnXGaM2eOyldeeWXo4+Psw8r1XHfffbfK48aNq/ZYYuDyefEClFiNn3zyySrbOluxYoXK9erVi+3atl/F9mh98MEHKr/77ruh5/vqq69Ubt++fQ6ji4wajyaxGreWLVumcs+ePVW2NW7XOfK5Ftbo0aNVtv1kI0aMUPmJJ57wNpZKUOPZi62+N2zYoHL//v1VXrVqVVyX8u6oo45S+a233lK5Y8eOSQ7Hor6jSew1fNeuXSpH7e1r3ry5yvfff7/KV111VWb7s88+U/vs88+aMmWKyu+9957Kdk1c+57KZ39ZJSqtcT7pAgAAAACPmHQBAAAAgEdMugAAAADAo9T0dG3btk3lzp07q/zrr7+q7LOn68gjj1TZrmfx9NNPq1y/fn2Va9euXe2xxIB7paPJW0+XvZ/57LPPVjnOfpa3335b5d9++y308fa+7KFDh6o8ceJElROueWo8mrz1dG3ZskXl8ePHq/z444+rXFpaqvJll10W21hsH6J9vtkaXr16tcr2OeEZNZ49b/X9+++/q3zqqaeqHLb+p2916tRR2a4DafspO3To4HtIUVDf0ST2Gm7nBHYtRbsuV1Vq1dLLAVd8HbXPrz179kQ6t/Xqq6+qnOe1FenpAgAAAICkMekCAAAAAI+YdAEAAACAR6np6bK+/fZblefOnauyXRsrzp6uefPmqWzX6kg57pWOJrEa/+ijj1S290rbNSd8ss+XZs2aqfzAAw+oXHFtjRSgxqPJ2+u4tXXrVpVtv+zGjRtVHjt2rMqjRo066Lltf4Bd82vQoEGh13rwwQdVvvXWWw96rQRQ49lLrL5tzfTp00dln+t4DRgwIDQPHjzY27U9oL6jydtr+NKlS1Xu3bt3nkbyby+88ILKQ4YMUTmXeUEM6OkCAAAAgKQx6QIAAAAAj5h0AQAAAIBHqe3pqsqaNWtUnj59usozZ85UuWJPysiRI9U++/9B69atVbbrX6Qc90pHk7ca3759u8r2XmnbA5aLMWPGqNy9e3eVbW9CylHj0aT2dXzHjh0q33TTTSovWLBA5eOPPz6zPXr0aLXv+uuvV7mqtejs2nMPP/ywyk2aNAk93jNqPHt5q+8NGzao/P7776t86aWXhh5ve1Dse5OK2rdvr7JdH7TAUN/R5K3G7ftj29fYsmXLxMby/PPPq2xfw51LVVnR0wUAAAAASWPSBQAAAAAeFezthTioVH2+WgCo8cJDjUdTMDW+e/dulcvKylS+5557MtulpaVqn/3Kd8ve6tWqVSuV8/z1whY1nr2CqW9kUN/RpKbG7Wu0vd1w3bp1KttbZs8666zM9gUXXKD29erVK/Ta9jU6ZbcTWtxeCAAAAABJY9IFAAAAAB4x6QIAAAAAj+jpKj6pvsk1hajxwkONR0ONFx5qPHvUd+GhvqOhxgsPPV0AAAAAkDQmXQAAAADgEZMuAAAAAPCISRcAAAAAeMSkCwAAAAA8YtIFAAAAAB4x6QIAAAAAj5h0AQAAAIBHTLoAAAAAwCMmXQAAAADgEZMuAAAAAPDIBUGQ7zEAAAAAQNHiky4AAAAA8IhJFwAAAAB4xKQLAAAAADxi0gUAAAAAHjHpAgAAAACPmHQBAAAAgEf/D5gIJKyGkkTxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x144 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_train,dataset_test,x_train_origin,y_train_origin,x_test_origin,y_test_origin = buildDataSet()\n",
    "print(\"Checking shapes for class 0 (train) : \",dataset_train[0].shape)\n",
    "print(\"Checking shapes for class 0 (test) : \",dataset_test[0].shape)\n",
    "print(\"Checking first samples\")\n",
    "for i in range(2):\n",
    "    DrawPics(dataset_train[i],5,template='Train {}',classnumber=i)\n",
    "    DrawPics(dataset_test[i],5,template='Test {}',classnumber=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Neural Network for computing triplet similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(input_shape, embeddingsize):\n",
    "    '''\n",
    "    Define the neural network to learn image similarity\n",
    "    Input : \n",
    "            input_shape : shape of input images\n",
    "            embeddingsize : vectorsize used to encode our picture   \n",
    "    '''\n",
    "     # Convolutional Neural Network\n",
    "    network = Sequential()\n",
    "    network.add(Conv2D(128, (7,7), activation='relu',\n",
    "                     input_shape=input_shape,\n",
    "                     kernel_initializer='he_uniform',\n",
    "                     kernel_regularizer=l2(2e-4)))\n",
    "    network.add(MaxPooling2D())\n",
    "    network.add(Conv2D(128, (3,3), activation='relu', kernel_initializer='he_uniform',\n",
    "                     kernel_regularizer=l2(2e-4)))\n",
    "    network.add(MaxPooling2D())\n",
    "    network.add(Conv2D(256, (3,3), activation='relu', kernel_initializer='he_uniform',\n",
    "                     kernel_regularizer=l2(2e-4)))\n",
    "    network.add(Flatten())\n",
    "    network.add(Dense(4096, activation='relu',\n",
    "                   kernel_regularizer=l2(1e-3),\n",
    "                   kernel_initializer='he_uniform'))\n",
    "    \n",
    "    \n",
    "    network.add(Dense(embeddingsize, activation=None,\n",
    "                   kernel_regularizer=l2(1e-3),\n",
    "                   kernel_initializer='he_uniform'))\n",
    "    \n",
    "    #Force the encoding to live on the d-dimentional hypershpere\n",
    "    network.add(Lambda(lambda x: K.l2_normalize(x,axis=-1)))\n",
    "    \n",
    "    return network\n",
    "\n",
    "class TripletLossLayer(Layer):\n",
    "    def __init__(self, alpha, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        super(TripletLossLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def triplet_loss(self, inputs):\n",
    "        anchor, positive, negative = inputs\n",
    "        p_dist = K.sum(K.square(anchor-positive), axis=-1)\n",
    "        n_dist = K.sum(K.square(anchor-negative), axis=-1)\n",
    "        return K.sum(K.maximum(p_dist - n_dist + self.alpha, 0), axis=0)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        loss = self.triplet_loss(inputs)\n",
    "        self.add_loss(loss)\n",
    "        return loss\n",
    "\n",
    "def build_model(input_shape, network, margin=0.2):\n",
    "    '''\n",
    "    Define the Keras Model for training \n",
    "        Input : \n",
    "            input_shape : shape of input images\n",
    "            network : Neural network to train outputing embeddings\n",
    "            margin : minimal distance between Anchor-Positive and Anchor-Negative for the lossfunction (alpha)\n",
    "    \n",
    "    '''\n",
    "     # Define the tensors for the three input images\n",
    "    anchor_input = Input(input_shape, name=\"anchor_input\")\n",
    "    positive_input = Input(input_shape, name=\"positive_input\")\n",
    "    negative_input = Input(input_shape, name=\"negative_input\") \n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the three images\n",
    "    encoded_a = network(anchor_input)\n",
    "    encoded_p = network(positive_input)\n",
    "    encoded_n = network(negative_input)\n",
    "    \n",
    "    #TripletLoss Layer\n",
    "    loss_layer = TripletLossLayer(alpha=margin,name='triplet_loss_layer')([encoded_a,encoded_p,encoded_n])\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    network_train = Model(inputs=[anchor_input,positive_input,negative_input],outputs=loss_layer)\n",
    "    \n",
    "    # return the model\n",
    "    return network_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tony/opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/engine/training_utils.py:819: UserWarning: Output triplet_loss_layer missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to triplet_loss_layer.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 10)           4688522     anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "triplet_loss_layer (TripletLoss [(None, 10), (None,  0           sequential_1[1][0]               \n",
      "                                                                 sequential_1[2][0]               \n",
      "                                                                 sequential_1[3][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,688,522\n",
      "Trainable params: 4,688,522\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ae0cd2d43862>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnetwork_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnetwork_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'02 model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mn_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \"\"\"\n\u001b[1;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[0;32m--> 240\u001b[0;31m                        expand_nested, dpi)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dashed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ML/lib/python3.7/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         raise ImportError(\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;34m'Failed to import `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;34m'Please install `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "network = build_network(input_shape,embeddingsize=10)\n",
    "network_train = build_model(input_shape,network)\n",
    "optimizer = Adam(lr = 0.00006)\n",
    "network_train.compile(loss=None,optimizer=optimizer)\n",
    "network_train.summary()\n",
    "#plot_model(network_train,show_shapes=True, show_layer_names=True, to_file='02 model.png')\n",
    "#print(network_train.metrics_names)\n",
    "n_iteration=0\n",
    "network_train.load_weights('mnist-160k_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](02 model.png \" \")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing our NN with dummy image\n",
    "featured_img = network.predict(np.ones((1,img_rows,img_cols,1)))\n",
    "print(featured_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing batch for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_random(batch_size,s=\"train\"):\n",
    "    \"\"\"\n",
    "    Create batch of APN triplets with a complete random strategy\n",
    "    \n",
    "    Arguments:\n",
    "    batch_size -- integer \n",
    "\n",
    "    Returns:\n",
    "    triplets -- list containing 3 tensors A,P,N of shape (batch_size,w,h,c)\n",
    "    \"\"\"\n",
    "    if s == 'train':\n",
    "        X = dataset_train\n",
    "    else:\n",
    "        X = dataset_test\n",
    "\n",
    "    m, w, h,c = X[0].shape\n",
    "    \n",
    "    \n",
    "    # initialize result\n",
    "    triplets=[np.zeros((batch_size,h, w,c)) for i in range(3)]\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        #Pick one random class for anchor\n",
    "        anchor_class = np.random.randint(0, nb_classes)\n",
    "        nb_sample_available_for_class_AP = X[anchor_class].shape[0]\n",
    "        \n",
    "        #Pick two different random pics for this class => A and P\n",
    "        [idx_A,idx_P] = np.random.choice(nb_sample_available_for_class_AP,size=2,replace=False)\n",
    "        \n",
    "        #Pick another class for N, different from anchor_class\n",
    "        negative_class = (anchor_class + np.random.randint(1,nb_classes)) % nb_classes\n",
    "        nb_sample_available_for_class_N = X[negative_class].shape[0]\n",
    "        \n",
    "        #Pick a random pic for this negative class => N\n",
    "        idx_N = np.random.randint(0, nb_sample_available_for_class_N)\n",
    "\n",
    "        triplets[0][i,:,:,:] = X[anchor_class][idx_A,:,:,:]\n",
    "        triplets[1][i,:,:,:] = X[anchor_class][idx_P,:,:,:]\n",
    "        triplets[2][i,:,:,:] = X[negative_class][idx_N,:,:,:]\n",
    "\n",
    "    return triplets\n",
    "\n",
    "def drawTriplets(tripletbatch, nbmax=None):\n",
    "    \"\"\"display the three images for each triplets in the batch\n",
    "    \"\"\"\n",
    "    labels = [\"Anchor\", \"Positive\", \"Negative\"]\n",
    "\n",
    "    if (nbmax==None):\n",
    "        nbrows = tripletbatch[0].shape[0]\n",
    "    else:\n",
    "        nbrows = min(nbmax,tripletbatch[0].shape[0])\n",
    "                 \n",
    "    for row in range(nbrows):\n",
    "        fig=plt.figure(figsize=(16,2))\n",
    "    \n",
    "        for i in range(3):\n",
    "            subplot = fig.add_subplot(1,3,i+1)\n",
    "            axis(\"off\")\n",
    "            plt.imshow(tripletbatch[i][row,:,:,0],vmin=0, vmax=1,cmap='Greys')\n",
    "            subplot.title.set_text(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dist(a,b):\n",
    "    return np.sum(np.square(a-b))\n",
    "\n",
    "def get_batch_hard(draw_batch_size,hard_batchs_size,norm_batchs_size,network,s=\"train\"):\n",
    "    \"\"\"\n",
    "    Create batch of APN \"hard\" triplets\n",
    "    \n",
    "    Arguments:\n",
    "    draw_batch_size -- integer : number of initial randomly taken samples   \n",
    "    hard_batchs_size -- interger : select the number of hardest samples to keep\n",
    "    norm_batchs_size -- interger : number of random samples to add\n",
    "\n",
    "    Returns:\n",
    "    triplets -- list containing 3 tensors A,P,N of shape (hard_batchs_size+norm_batchs_size,w,h,c)\n",
    "    \"\"\"\n",
    "    if s == 'train':\n",
    "        X = dataset_train\n",
    "    else:\n",
    "        X = dataset_test\n",
    "\n",
    "    m, w, h,c = X[0].shape\n",
    "    \n",
    "    \n",
    "    #Step 1 : pick a random batch to study\n",
    "    studybatch = get_batch_random(draw_batch_size,s)\n",
    "    \n",
    "    #Step 2 : compute the loss with current network : d(A,P)-d(A,N). The alpha parameter here is omited here since we want only to order them\n",
    "    studybatchloss = np.zeros((draw_batch_size))\n",
    "    \n",
    "    #Compute embeddings for anchors, positive and negatives\n",
    "    A = network.predict(studybatch[0])\n",
    "    P = network.predict(studybatch[1])\n",
    "    N = network.predict(studybatch[2])\n",
    "    \n",
    "    #Compute d(A,P)-d(A,N)\n",
    "    studybatchloss = np.sum(np.square(A-P),axis=1) - np.sum(np.square(A-N),axis=1)\n",
    "    \n",
    "    #Sort by distance (high distance first) and take the \n",
    "    selection = np.argsort(studybatchloss)[::-1][:hard_batchs_size]\n",
    "    \n",
    "    #Draw other random samples from the batch\n",
    "    selection2 = np.random.choice(np.delete(np.arange(draw_batch_size),selection),norm_batchs_size,replace=False)\n",
    "    \n",
    "    selection = np.append(selection,selection2)\n",
    "    \n",
    "    triplets = [studybatch[0][selection,:,:,:], studybatch[1][selection,:,:,:], studybatch[2][selection,:,:,:]]\n",
    "    \n",
    "    return triplets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = get_batch_random(2)\n",
    "print(\"Checking batch width, should be 3 : \",len(triplets))\n",
    "print(\"Shapes in the batch A:{0} P:{1} N:{2}\".format(triplets[0].shape, triplets[1].shape, triplets[2].shape))\n",
    "drawTriplets(triplets)\n",
    "hardtriplets = get_batch_hard(50,1,1,network)\n",
    "print(\"Shapes in the hardbatch A:{0} P:{1} N:{2}\".format(hardtriplets[0].shape, hardtriplets[1].shape, hardtriplets[2].shape))\n",
    "drawTriplets(hardtriplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "evaluate_every = 1000 # interval for evaluating on one-shot tasks\n",
    "batch_size = 32\n",
    "n_iter = 80000 # No. of training iterations\n",
    "n_val = 250 # how many one-shot tasks to validate on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation / evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def compute_probs(network,X,Y):\n",
    "    '''\n",
    "    Input\n",
    "        network : current NN to compute embeddings\n",
    "        X : tensor of shape (m,w,h,1) containing pics to evaluate\n",
    "        Y : tensor of shape (m,) containing true class\n",
    "        \n",
    "    Returns\n",
    "        probs : array of shape (m,m) containing distances\n",
    "    \n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    nbevaluation = int(m*(m-1)/2)\n",
    "    probs = np.zeros((nbevaluation))\n",
    "    y = np.zeros((nbevaluation))\n",
    "    \n",
    "    #Compute all embeddings for all pics with current network\n",
    "    embeddings = network.predict(X)\n",
    "    \n",
    "    size_embedding = embeddings.shape[1]\n",
    "    \n",
    "    #For each pics of our dataset\n",
    "    k = 0\n",
    "    for i in range(m):\n",
    "            #Against all other images\n",
    "            for j in range(i+1,m):\n",
    "                #compute the probability of being the right decision : it should be 1 for right class, 0 for all other classes\n",
    "                probs[k] = -compute_dist(embeddings[i,:],embeddings[j,:])\n",
    "                if (Y[i]==Y[j]):\n",
    "                    y[k] = 1\n",
    "                    #print(\"{3}:{0} vs {1} : {2}\\tSAME\".format(i,j,probs[k],k))\n",
    "                else:\n",
    "                    y[k] = 0\n",
    "                    #print(\"{3}:{0} vs {1} : \\t\\t\\t{2}\\tDIFF\".format(i,j,probs[k],k))\n",
    "                k += 1\n",
    "    return probs,y\n",
    "#probs,yprobs = compute_probs(network,x_test_origin[:10,:,:,:],y_test_origin[:10])\n",
    "\n",
    "def compute_metrics(probs,yprobs):\n",
    "    '''\n",
    "    Returns\n",
    "        fpr : Increasing false positive rates such that element i is the false positive rate of predictions with score >= thresholds[i]\n",
    "        tpr : Increasing true positive rates such that element i is the true positive rate of predictions with score >= thresholds[i].\n",
    "        thresholds : Decreasing thresholds on the decision function used to compute fpr and tpr. thresholds[0] represents no instances being predicted and is arbitrarily set to max(y_score) + 1\n",
    "        auc : Area Under the ROC Curve metric\n",
    "    '''\n",
    "    # calculate AUC\n",
    "    auc = roc_auc_score(yprobs, probs)\n",
    "    # calculate roc curve\n",
    "    fpr, tpr, thresholds = roc_curve(yprobs, probs)\n",
    "    \n",
    "    return fpr, tpr, thresholds,auc\n",
    "\n",
    "def compute_interdist(network):\n",
    "    '''\n",
    "    Computes sum of distances between all classes embeddings on our reference test image: \n",
    "        d(0,1) + d(0,2) + ... + d(0,9) + d(1,2) + d(1,3) + ... d(8,9)\n",
    "        A good model should have a large distance between all theses embeddings\n",
    "        \n",
    "    Returns:\n",
    "        array of shape (nb_classes,nb_classes) \n",
    "    '''\n",
    "    res = np.zeros((nb_classes,nb_classes))\n",
    "    \n",
    "    ref_images = np.zeros((nb_classes,img_rows,img_cols,1))\n",
    "    \n",
    "    #generates embeddings for reference images\n",
    "    for i in range(nb_classes):\n",
    "        ref_images[i,:,:,:] = dataset_test[i][0,:,:,:]\n",
    "    ref_embeddings = network.predict(ref_images)\n",
    "    \n",
    "    for i in range(nb_classes):\n",
    "        for j in range(nb_classes):\n",
    "            res[i,j] = dist(ref_embeddings[i],ref_embeddings[j])\n",
    "    return res\n",
    "\n",
    "def draw_interdist(network,n_iteration):\n",
    "    interdist = compute_interdist(network)\n",
    "    \n",
    "    data = []\n",
    "    for i in range(nb_classes):\n",
    "        data.append(np.delete(interdist[i,:],[i]))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Evaluating embeddings distance from each other after {0} iterations'.format(n_iteration))\n",
    "    ax.set_ylim([0,3])\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Distance')\n",
    "    ax.boxplot(data,showfliers=False,showbox=True)\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.xticks(locs,np.arange(nb_classes))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1],idx-1\n",
    "    else:\n",
    "        return array[idx],idx\n",
    "    \n",
    "def draw_roc(fpr, tpr,thresholds):\n",
    "    #find threshold\n",
    "    targetfpr=1e-3\n",
    "    _, idx = find_nearest(fpr,targetfpr)\n",
    "    threshold = thresholds[idx]\n",
    "    recall = tpr[idx]\n",
    "    \n",
    "    \n",
    "    # plot no skill\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.title('AUC: {0:.3f}\\nSensitivity : {2:.1%} @FPR={1:.0e}\\nThreshold={3})'.format(auc,targetfpr,recall,abs(threshold) ))\n",
    "    # show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on an untrained network\n",
    "probs,yprob = compute_probs(network,x_test_origin[:500,:,:,:],y_test_origin[:500])\n",
    "fpr, tpr, thresholds,auc = compute_metrics(probs,yprob)\n",
    "draw_roc(fpr, tpr,thresholds)\n",
    "draw_interdist(network,n_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawTestImage(network, images, refidx=0):\n",
    "    '''\n",
    "    Evaluate some pictures vs some samples in the test set\n",
    "        image must be of shape(1,w,h,c)\n",
    "    \n",
    "    Returns\n",
    "        scores : resultat des scores de similarités avec les images de base => (N)\n",
    "    \n",
    "    '''\n",
    "    N=4\n",
    "    _, w,h,c = dataset_test[0].shape\n",
    "    nbimages=images.shape[0]\n",
    "    \n",
    "    #generates embedings for given images\n",
    "    image_embedings = network.predict(images)\n",
    "    \n",
    "    #generates embedings for reference images\n",
    "    ref_images = np.zeros((nb_classes,w,h,c))\n",
    "    for i in range(nb_classes):\n",
    "        ref_images[i,:,:,:] = dataset_test[i][refidx,:,:,:]\n",
    "    ref_embedings = network.predict(ref_images)\n",
    "            \n",
    "    for i in range(nbimages):\n",
    "        #Prepare the figure\n",
    "        fig=plt.figure(figsize=(16,2))\n",
    "        subplot = fig.add_subplot(1,nb_classes+1,1)\n",
    "        axis(\"off\")\n",
    "        plotidx = 2\n",
    "            \n",
    "        #Draw this image    \n",
    "        plt.imshow(images[i,:,:,0],vmin=0, vmax=1,cmap='Greys')\n",
    "        subplot.title.set_text(\"Test image\")\n",
    "            \n",
    "        for ref in range(nb_classes):\n",
    "            #Compute distance between this images and references\n",
    "            dist = compute_dist(image_embedings[i,:],ref_embedings[ref,:])\n",
    "            #Draw\n",
    "            subplot = fig.add_subplot(1,nb_classes+1,plotidx)\n",
    "            axis(\"off\")\n",
    "            plt.imshow(ref_images[ref,:,:,0],vmin=0, vmax=1,cmap='Greys')\n",
    "            subplot.title.set_text((\"Class {0}\\n{1:.3e}\".format(ref,dist)))\n",
    "            plotidx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    DrawTestImage(network,np.expand_dims(dataset_train[i][0,:,:,:],axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "t_start = time.time()\n",
    "dummy_target = [np.zeros((batch_size,15)) for i in range(3)]\n",
    "for i in range(1, n_iter+1):\n",
    "    triplets = get_batch_hard(200,16,16,network)\n",
    "    loss = network_train.train_on_batch(triplets, None)\n",
    "    n_iteration += 1\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"[{3}] Time for {0} iterations: {1:.1f} mins, Train Loss: {2}\".format(i, (time.time()-t_start)/60.0,loss,n_iteration))\n",
    "        probs,yprob = compute_probs(network,x_test_origin[:n_val,:,:,:],y_test_origin[:n_val])\n",
    "        #fpr, tpr, thresholds,auc = compute_metrics(probs,yprob)\n",
    "        #draw_roc(fpr, tpr)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full evaluation\n",
    "probs,yprob = compute_probs(network,x_test_origin,y_test_origin)\n",
    "fpr, tpr, thresholds,auc = compute_metrics(probs,yprob)\n",
    "draw_roc(fpr, tpr,thresholds)\n",
    "draw_interdist(network,n_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_interdist(network,n_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_interdist(network,n_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_interdist(network,n_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    DrawTestImage(network,np.expand_dims(dataset_train[i][0,:,:,:],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_interdist(network,n_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
