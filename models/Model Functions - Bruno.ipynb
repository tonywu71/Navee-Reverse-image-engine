{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aLQkIAtP7JXJ"
   },
   "source": [
    "\n",
    "# Model Functions\n",
    "\n",
    "First Part based on Tony and Matheus code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "25HGHMkJ7JXM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import io\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "#TensorBoard notebook extension and clear any logs from previous runs\n",
    "%load_ext tensorboard\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YEfb5boU7UYf",
    "outputId": "b9869f34-48c2-4e37-e728-97d2af9dda9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "yKBYjbis8exu",
    "outputId": "ac1417b0-1cd9-4e61-d556-56eb52a7e601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 101_Object_Categories for image notebooks\n",
      "######################################################################## 100.0%\n",
      "101_ObjectCategories  sample_data\n"
     ]
    }
   ],
   "source": [
    "#for colab running\n",
    "if True:\n",
    "  !echo \"Downloading 101_Object_Categories for image notebooks\"\n",
    "  !curl -L -o 101_ObjectCategories.tar.gz --progress-bar http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz\n",
    "  !tar -xzf 101_ObjectCategories.tar.gz\n",
    "  !rm 101_ObjectCategories.tar.gz\n",
    "  !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "id": "KWYlpePy85Ox",
    "outputId": "c1499876-c253-45d2-ca54-1c4e32b33be0",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3a472480e991>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'101_ObjectCategories'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dataset not found üëéüèª'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Dataset found ü§ôüèª'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Dataset not found üëéüèª"
     ]
    }
   ],
   "source": [
    "data_path = '101_ObjectCategories'\n",
    "\n",
    "assert os.path.isdir(data_path), 'Dataset not found üëéüèª'\n",
    "print ('Dataset found ü§ôüèª')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iqMYH4vZ95Q2"
   },
   "source": [
    "## Some Functions\n",
    "\n",
    "\n",
    "*   generate_model\n",
    "*   load_weights\n",
    "*   compile_model\n",
    "*   train_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m76iZ-fB9aV7"
   },
   "outputs": [],
   "source": [
    "def generate_model(hparams, resnet50model =True):\n",
    "\n",
    "    '''\n",
    "    A function that generates the model based on the hyperparameters that are given.\n",
    "    The model is not yet compiled, neither with the weights\n",
    "\n",
    "    Inputs:\n",
    "      - resnetmodel: a boolean that is by default True saying that the model use is ResNet50, if you want to use other model pass it in this argument\n",
    "      - hparams: a dictionnary containning, at least, the following hyperparameters (in parenthesis is the hyperparameter key)\n",
    "          - number of dense layers ('HP_NUM_DENSEUNITS'), list of numbers\n",
    "          - number of units in the dense layer ('HP_NUM_UNITS'), list of numbers\n",
    "          - number of dropout layers ('HP_DROPOUT_UNITS'), list of numbers\n",
    "          - dropout rate in the dropouts layer ('HP_DROPOUT'),listof numbers lower than 1\n",
    "          - number of trainable layers ('HP_TRAINABLES'), list of numbers\n",
    "\n",
    "\n",
    "    Output:\n",
    "      - a model not compiled but with the hiperparameters chosen\n",
    "\n",
    "    '''\n",
    "\n",
    "    #Things that can be added to the function: order of dropout and dense layers, activation function choice\n",
    "\n",
    "    #model creating and adding dense and dropout layers\n",
    "    model = Sequential()\n",
    "    if type(resnet50model)== bool:\n",
    "        model.add(ResNet50(include_top = False, weights = 'imagenet'))\n",
    "    else:\n",
    "        model.add(resnet50model)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    for i in hparams['HP_DROPOUT_UNITS']:\n",
    "        model.add(hparams['HP_DROPOUT'])\n",
    "    for i in hparams['HP_NUM_DENSEUNITS']:\n",
    "        model.add(Dense(hparams['HP_NUM_UNITS'],activation='relu'))\n",
    "    model.add(Dense(102,activation='softmax'))\n",
    "\n",
    "    #model layers trainable \n",
    "    model.layers[-5].layers[-1].trainable = False\n",
    "    for i in model.layers[-5].layers :\n",
    "        i.trainable = False\n",
    "    layer_number = -1\n",
    "    for i in range(hparams['HP_TRAINABLES']):\n",
    "        layer_number-=i\n",
    "        model.layers[-5].layers[layer_number].trainable = True\n",
    "\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QrReOHuDP03s"
   },
   "outputs": [],
   "source": [
    "def load_weights(model,weights_filepath):\n",
    "    '''\n",
    "    A function that loads weight to the model.\n",
    "    The function raise an exception if the file is not a .h5\n",
    "\n",
    "    Inputs:\n",
    "      - model: a generated keras model\n",
    "      - weights_filepath: the filepath to weights data, must be a .h5 file\n",
    "\n",
    "    Output:\n",
    "      - a model with weights\n",
    "    '''\n",
    "    if weights_filepath.endswith('.h5'):\n",
    "        return model.load_weights('weigths_filepath')\n",
    "    else:\n",
    "        print('Is not a .h5 file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZKLLoMYWBU4"
   },
   "outputs": [],
   "source": [
    "def compile_model(model,hparams,metrics_list):\n",
    "\n",
    "    '''\n",
    "    A function that compiles the model according to the hyperparameters defined.\n",
    "\n",
    "    Inputs:\n",
    "      - model: a generated keras model\n",
    "      - hparams: a dictionnary containning, at least, the following hyperparameters (in parenthesis is the hyperparameter key)\n",
    "          - the loss function ('HP_LOSS_FUNCTION'), list of loss functions types in keras\n",
    "          - the optimizer ('HP_OPTMIZER'), list of optmizes in keras\n",
    "      - metrics_list: the metrics for the model\n",
    "\n",
    "    Output:\n",
    "      - a model with weights\n",
    "    '''\n",
    "    model.compile(loss= hparams['HP_LOSS_FUNCTION'],\n",
    "                optimizer= hparams['HP_OPTMIZER'],\n",
    "                metrics= metrics_list)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AdVj5wVOYmbv"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_generator, validation_generator, hparams, callbacks = False, modelpath = False):\n",
    "    '''\n",
    "  A function that trains the model with the training data.\n",
    "  Can return only the model if no pathway is specified.\n",
    "  Save the model in a pathway if pathway specified.\n",
    "\n",
    "  Inputs:\n",
    "      - model: a generated keras model already compiled\n",
    "      - train_generator: the train data generated\n",
    "      - validation_generator: the validation data generated\n",
    "      - hparams: a dictionnary containning, at least, the following hyperparameters (in parenthesis is the hyperparameter key)\n",
    "          - number of epochs ('HP_EPOCHS'), list of numbers\n",
    "      - callback: a boolean. If there is a tensorboard callback and a logdir, specified in the following variables the parameters must be turn True:\n",
    "          - tensorboard_callback\n",
    "          - logdir\n",
    "      - modelpath: False if it is not to save the model. If it is to save it must be specified the pathway as a string is this argument\n",
    "      \n",
    "     \n",
    "          \n",
    "    \n",
    "  Output:\n",
    "      - a model trained\n",
    "      - a file .h5 with the weights of the model\n",
    "  '''\n",
    "    if callbacks:\n",
    "        model.fit_generator(generator=train_generator,\n",
    "                        steps_per_epoch=len(train_generator),\n",
    "                        epochs=hparams['HP_EPOCHS'],\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps= len(validation_generator),\n",
    "                        verbose=True,\n",
    "                        shuffle=True,\n",
    "                        callbacks=[tensorboard_callback])\n",
    "    else:\n",
    "        model.fit_generator(generator=train_generator,\n",
    "                        steps_per_epoch=len(train_generator),\n",
    "                        epochs=hparams['HP_EPOCHS'],\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps= len(validation_generator),\n",
    "                        verbose=True,\n",
    "                        shuffle=True)\n",
    "    if type(modelpath) == bool:\n",
    "        if not modelpath:\n",
    "            return model\n",
    "    else:\n",
    "        model.save(modelpath)\n",
    "        print('Saved trained model at %s ' % model_path)\n",
    "        return model\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Model Functions - Bruno.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
